{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUdxrsQ1oQUY"
      },
      "source": [
        "![](2024-08-14-18-07-11.png)\n",
        "\n",
        "# IMAGE SEGMENTATION \n",
        "## Author: Diversa\n",
        "## Last Update: 22/8/2024\n",
        "## Proyect: Feminist Urban Sense\n",
        "## Contact: hello@diversa.studio\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Segmentation\n",
        "\n",
        "## Objectives\n",
        "1. **Implement a YOLO-based model for image segmentation:** This notebook aims to detect and classify various categories related to safety, proximity, diversity, autonomy, vitality, and representativity using the YOLOWorld model.\n",
        "\n",
        "## Methodology\n",
        "\n",
        "### 1. Environment Preparation\n",
        "- **Library Installation:** The necessary libraries, including `inference-gpu[yolo-world]` and `supervision`, are installed to support the YOLO model implementation.\n",
        "\n",
        "### 2. Model Configuration\n",
        "- **YOLOWorld Model:** The notebook configures the YOLOWorld model using the `yolo_world/l` model ID for segmentation tasks.\n",
        "\n",
        "### 3. Image Segmentation Categories\n",
        "- **Category Definitions:** The notebook defines six key categories for segmentation:\n",
        "  - **Safety:** Includes items like \"Light poles\" and \"Streetlights.\"\n",
        "  - **Proximity:** Includes items like \"Bus stop\" and \"Transit stop.\"\n",
        "  - **Diversity:** Includes items like \"Playground\" and \"Jungle gym.\"\n",
        "  - **Autonomy:** Includes items like \"Bench\" and \"Outdoor bench.\"\n",
        "  - **Vitality:** Includes items like \"Playground\" and \"Play structure.\"\n",
        "  - **Representativity:** Includes items like \"Police station\" and \"Precinct.\"\n",
        "\n",
        "- **Segmentation Process:** For each category, images are processed using the defined YOLO model to detect and classify relevant objects.\n",
        "\n",
        "### 4. Data Analysis\n",
        "- **CSV Data Handling:** The results of the segmentation are stored in CSV files, which are then analyzed to extract insights related to the different categories.\n",
        "- **Category-wise Analysis:** The notebook provides a detailed analysis of the results for each category, using the processed data stored in CSV files.\n",
        "\n",
        "## Important Aspects\n",
        "- **Comprehensive Segmentation:** This notebook effectively segments and classifies images into predefined categories using a state-of-the-art YOLO model.\n",
        "- **Scalability:** The methods used can be scaled to handle larger datasets or different categories.\n",
        "- **Documentation:** Each step is well-documented to ensure clarity and reproducibility.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FatCZlJ4oQUb"
      },
      "source": [
        "### 1.- Enviroment Preparation\n",
        "Instalations and Imports of libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0esZFrx0iVZ",
        "outputId": "7d1b25f6-34f7-4c89-845c-8a635a398396"
      },
      "outputs": [],
      "source": [
        "!pip install -q inference-gpu[yolo-world]==0.9.12rc1\n",
        "!pip install -q supervision==0.19.0rc3\n",
        "\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import supervision as sv\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from tqdm import tqdm\n",
        "from inference.models.yolo_world.yolo_world import YOLOWorld\n",
        "\n",
        "# Se traen las librerias del google para realizar la conexion con el drive\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\") # Se realiza la peticion para conexion a la cuenta de google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmQf8V4aoQUc"
      },
      "source": [
        "### 2.- Model Values Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN7uvDRQ1208"
      },
      "outputs": [],
      "source": [
        "model = YOLOWorld(model_id=\"yolo_world/l\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def procesar_imagenes_yolo(path_origen, path_destino):\n",
        "    if not os.path.exists(path_destino):\n",
        "        os.makedirs(path_destino)\n",
        "\n",
        "    detecciones_lista = []\n",
        "    summary_list = []\n",
        "\n",
        "    imagenes = [f for f in os.listdir(path_origen) if os.path.isfile(os.path.join(path_origen, f))]\n",
        "\n",
        "    for imagen in imagenes:\n",
        "        imagen_path = os.path.join(path_origen, imagen)\n",
        "        image = cv2.imread(imagen_path)\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Error, image: '{image}' was not valid and will be omited\")\n",
        "            continue\n",
        "\n",
        "        results = model.infer(image)\n",
        "        detections = sv.Detections.from_inference(results)\n",
        "\n",
        "        BOUNDING_BOX_ANNOTATOR = sv.BoundingBoxAnnotator(thickness=2)\n",
        "        LABEL_ANNOTATOR = sv.LabelAnnotator(text_thickness=2, text_scale=1, text_color=sv.Color.BLACK)\n",
        "        annotated_image = image.copy()\n",
        "        annotated_image = BOUNDING_BOX_ANNOTATOR.annotate(annotated_image, detections)\n",
        "        annotated_image = LABEL_ANNOTATOR.annotate(annotated_image, detections)\n",
        "\n",
        "        imagen_destino_path = os.path.join(path_destino, imagen)\n",
        "        cv2.imwrite(imagen_destino_path, annotated_image)\n",
        "\n",
        "        detected_tags = []\n",
        "        for detection in detections:\n",
        "            x1, y1, x2, y2, confianza, etiqueta = detection\n",
        "            detecciones_lista.append({\n",
        "                'imagen': imagen,\n",
        "                'x1': x1,\n",
        "                'y1': y1,\n",
        "                'x2': x2,\n",
        "                'y2': y2,\n",
        "                'confianza': confianza,\n",
        "                'etiqueta': etiqueta\n",
        "            })\n",
        "            # Assuming 'etiqueta' is a dictionary, let's extract the label\n",
        "            if isinstance(etiqueta, dict):\n",
        "                # Replace 'label' with the actual key that contains the label in your etiqueta dictionary\n",
        "                label = etiqueta.get('label', str(etiqueta))\n",
        "            else:\n",
        "                label = str(etiqueta)\n",
        "            detected_tags.append(label)\n",
        "\n",
        "        summary_list.append({\n",
        "            'imagen': imagen,\n",
        "            'detected': ', '.join(set(detected_tags))  # Use set to remove duplicates\n",
        "        })\n",
        "\n",
        "    sv.plot_image(annotated_image, (10, 10))\n",
        "\n",
        "    # Create and save the detailed DataFrame\n",
        "    df_detecciones = pd.DataFrame(detecciones_lista)\n",
        "    df_detecciones.to_csv(os.path.join(path_destino, 'ObjectDetected.csv'), index=False)\n",
        "\n",
        "    # Create and save the summary DataFrame\n",
        "    df_summary = pd.DataFrame(summary_list)\n",
        "    df_summary.to_csv(os.path.join(path_destino, 'DetectionSummary.csv'), index=False)\n",
        "\n",
        "    return df_detecciones, df_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJU7RFPxoQUd"
      },
      "source": [
        "### 3.- Images Segmentation Categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGomT2Fo3Br5"
      },
      "source": [
        "#### **SAFETY CATEGORIE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK2msz4CunfU"
      },
      "outputs": [],
      "source": [
        "pathOrigen = r\"'your_paths'\"\n",
        "path_destino = r\"'your_paths'\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UflJmfmfOPGi",
        "outputId": "32132405-9cad-4c76-edec-5017832990de"
      },
      "outputs": [],
      "source": [
        "model = YOLOWorld(model_id=\"yolo_world/l\")\n",
        "safety_classes = [\n",
        "    \"Light poles\", \"Streetlights,\", \"Lamp posts\",\n",
        "    \"Neon light\", \"Fluorescent light,\", \"LED sign\",\n",
        "    \"White light\", \"Halogen light,\", \"Daylight bulb\",\n",
        "    \"Yellow light\", \"Amber light,\", \"Sodium vapor light\",\n",
        "    \"Signage\", \"Directional sign,\", \"Traffic sign\",\n",
        "    \"CCTV\", \"Surveillance camera,\", \"Security camera\",\n",
        "    \"Marked crosswalk\", \"Zebra crossing,\", \"Pedestrian crossing\",\n",
        "    \"Ramps\", \"Incline plane,\", \"Access ramp\",\n",
        "    \"Handrail\", \"Guardrail,\", \"Safety rail\",\n",
        "    \"Stair handrail\", \"Balustrade,\", \"Railing\",\n",
        "    \"Elevator/Lift\", \"Escalator,\", \"Stair lift\",\n",
        "    \"Bush\", \"Shrub,\", \"Hedge\",\n",
        "    \"Trees\", \"Saplings,\", \"Shade trees\",\n",
        "    \"Maps\", \"Wayfinding map,\", \"City map\",\n",
        "    \"Pedestrian bridge\", \"Footbridge,\", \"Walkway bridge\",\n",
        "    \"Overpass\", \"Flyover,\", \"Pedestrian overpass\"\n",
        "]\n",
        "model.set_classes(safety_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sGwmjCmNNAcD",
        "outputId": "1dd9cbdf-e2d1-4eea-dbbe-e50ac1a5250e"
      },
      "outputs": [],
      "source": [
        "df_resultados = procesar_imagenes_yolo(pathOrigen, path_destino)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2mNGEN6N8F-"
      },
      "source": [
        "#### **PROXIMITY CATEGORIE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1kSeSQLyhP0"
      },
      "outputs": [],
      "source": [
        "pathOrigen = r\"'your_paths'\"\n",
        "path_destino = r\"'your_paths'\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-YaO6DFOuha"
      },
      "outputs": [],
      "source": [
        "model = YOLOWorld(model_id=\"yolo_world/l\")\n",
        "proximity_classes = [\n",
        "    \"Bus stop\", \"Transit stop\", \"Bus shelter\",\n",
        "    \"Metro stop\", \"Subway station\", \"Underground station\",\n",
        "    \"Bicycle lines\", \"Bike path\", \"Cycle lane\",\n",
        "    \"Bicycle parking\", \"Bike rack\", \"Cycle stand\",\n",
        "    \"Bicycle storage cage\", \"Bike locker\", \"Bicycle enclosure\",\n",
        "    \"Public toilet\", \"Restroom\", \"Lavatory\",\n",
        "    \"Local stores\", \"Corner shop\", \"Convenience store\",\n",
        "    \"Vendor stall\", \"Market stall\", \"Kiosk\",\n",
        "    \"Kiosks\", \"Booth\", \"Newsstand\",\n",
        "    \"Bus stop bench\", \"Waiting bench\", \"Transit seating\",\n",
        "    \"Bus stop roof\", \"Canopy\", \"Shelter roof\",\n",
        "    \"Ramp handrail\", \"Accessibility rail\", \"Incline handrail\",\n",
        "    \"Stair handrail\", \"Guardrail\", \"Banister\"\n",
        "]\n",
        "\n",
        "\n",
        "model.set_classes(proximity_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IipLECUNO4bt",
        "outputId": "d700c8c7-990f-4efe-f0a4-1f2dc8b690b9"
      },
      "outputs": [],
      "source": [
        "df_resultados = procesar_imagenes_yolo(pathOrigen, path_destino)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDPSaSdwPMjx"
      },
      "source": [
        "#### **DIVERSITY CATEGORIE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5BsxuNkzkcG"
      },
      "outputs": [],
      "source": [
        "pathOrigen = r\"'your_paths'\"\n",
        "path_destino = r\"'your_paths'\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkY5iAo8PPcn"
      },
      "outputs": [],
      "source": [
        "model = YOLOWorld(model_id=\"yolo_world/l\")\n",
        "diversity_classes = [\n",
        "    \"Playground\", \"Play area\", \"Jungle gym\",\n",
        "    \"Bench\", \"Park bench\", \"Garden seat\",\n",
        "    \"Seats\", \"Chair\", \"Stool\",\n",
        "    \"Table\", \"Dining table\", \"Picnic table\",\n",
        "    \"Coffee table\", \"Side table\", \"Accent table\",\n",
        "    \"Automatic teller machine\", \"ATM\", \"Cash machine\",\n",
        "    \"Payphone cabinets\", \"Phone booth\", \"Telephone kiosk\",\n",
        "    \"Parking meters\", \"Ticket machine\", \"Metered parking device\",\n",
        "    \"Vending and ticket machines\", \"Dispenser\", \"Ticket kiosk\"\n",
        "]\n",
        "model.set_classes(diversity_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "M_B8RKe-PV18",
        "outputId": "5dfc5bcf-b20a-4768-e0ac-31c66978463f"
      },
      "outputs": [],
      "source": [
        "df_resultados = procesar_imagenes_yolo(pathOrigen, path_destino)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF_FpXwJP0d2"
      },
      "source": [
        "#### **AUTONOMY CATEGORIE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzysbl490Ll_"
      },
      "outputs": [],
      "source": [
        "pathOrigen = r\"'your_paths'\"\n",
        "path_destino = r\"'your_paths'\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuV4wk9-Pt3E"
      },
      "outputs": [],
      "source": [
        "model = YOLOWorld(model_id=\"yolo_world/l\")\n",
        "autonomy_classes = [\n",
        "    \"Bench\", \"Park seat\", \"Outdoor bench\",\n",
        "    \"Seats\", \"Armchair\", \"Lounge chair\",\n",
        "    \"Table\", \"Picnic bench\", \"Patio table\",\n",
        "    \"Coffee table\", \"Tea table\", \"Cocktail table\",\n",
        "    \"Shelter\", \"Pavilion\", \"Gazebo\",\n",
        "    \"Sun umbrella\", \"Parasol\", \"Shade umbrella\",\n",
        "    \"Grassy\", \"Turf\", \"Lawn\",\n",
        "    \"Sandbox\", \"Sandpit\", \"Play pit\",\n",
        "    \"Cement box\", \"Concrete planter\", \"Stone container\",\n",
        "    \"Wood\", \"Timber\", \"Lumber\",\n",
        "    \"Metal box\", \"Steel container\", \"Aluminum box\",\n",
        "    \"Concrete bollards\", \"Stone bollard\", \"Traffic bollard\",\n",
        "    \"Metal bollards\", \"Steel post\", \"Iron bollard\",\n",
        "    \"Ramps\", \"Incline\", \"Gradient\",\n",
        "    \"Stair handrail\", \"Baluster\", \"Hand grip\",\n",
        "    \"Elevator/Lift\", \"Platform lift\", \"Hoist\"\n",
        "]\n",
        "\n",
        "model.set_classes(autonomy_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "o_Hr0M-PPxRI",
        "outputId": "6b75948c-8d86-40b2-e76a-993c2ea63345"
      },
      "outputs": [],
      "source": [
        "df_resultados = procesar_imagenes_yolo(pathOrigen, path_destino)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1zqLSv8QZ5f"
      },
      "source": [
        "#### **VITALITY CATEGORIE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXr1zh6N0zep"
      },
      "outputs": [],
      "source": [
        "pathOrigen = r\"'your_paths'\"\n",
        "path_destino = r\"'your_paths'\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2lzMsT6QOX6"
      },
      "outputs": [],
      "source": [
        "model = YOLOWorld(model_id=\"yolo_world/l\")\n",
        "vitality_classes = [\n",
        "    \"Playground\", \"Play structure\", \"Swing set\",\n",
        "    \"Bench\", \"Garden bench\", \"Outdoor seat\",\n",
        "    \"Table\", \"Picnic bench\", \"Coffee table\",\n",
        "    \"Parks\", \"Public garden\", \"Green space\",\n",
        "    \"Fountains\", \"Water feature\", \"Water spout\",\n",
        "    \"Skate\", \"Skateboard ramp\", \"Skate park\",\n",
        "    \"Busker\", \"Street performer\", \"Musician\"\n",
        "]\n",
        "\n",
        "model.set_classes(vitality_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "80rKLzHeQRYL",
        "outputId": "42b6c20f-10cd-461f-a4c4-e911e0d6dc74"
      },
      "outputs": [],
      "source": [
        "df_resultados = procesar_imagenes_yolo(pathOrigen, path_destino)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfdHk0Q7QyEq"
      },
      "source": [
        "#### **REPRESENTATIVITY CATEGORIE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rczLkJl708Xe"
      },
      "outputs": [],
      "source": [
        "pathOrigen = r\"'your_paths'\"\n",
        "path_destino = r\"'your_paths'\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fD6Eq1cQ1fT"
      },
      "outputs": [],
      "source": [
        "model = YOLOWorld(model_id=\"yolo_world/l\")\n",
        "representativity_classes = [\n",
        "    \"Police station\", \"Precinct\", \"Law enforcement office\",\n",
        "    \"Kiosks\", \"Information booth\", \"Concession stand\",\n",
        "    \"Vendor stall\", \"Market booth\", \"Food stall\",\n",
        "    \"Post boxes\", \"Mailbox\", \"Post office box\",\n",
        "    \"Graffiti\", \"Street art\", \"Wall mural\",\n",
        "    \"Mural\", \"Fresco\", \"Wall painting\",\n",
        "    \"Statue\", \"Monument\", \"Sculpture\",\n",
        "    \"Sculpture\", \"Carving\", \"Figurine\"\n",
        "]\n",
        "\n",
        "model.set_classes(representativity_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "2oYgev12Q46k",
        "outputId": "3d64ad2f-0f28-45ea-de1d-63c643c1aada"
      },
      "outputs": [],
      "source": [
        "df_resultados = procesar_imagenes_yolo(pathOrigen, path_destino)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eC2jG4QMUM1"
      },
      "source": [
        "### 4.- Data Analisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd3IwJJzoQUh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the list of directories where your CSV files are located\n",
        "paths = ['your_paths']  # Add your paths here\n",
        "\n",
        "# Function to unify detections in a single cell by 'imagen'\n",
        "def unify_detections(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Fill NaN values with empty strings\n",
        "    df['detected'] = df['detected'].fillna('')\n",
        "\n",
        "    # Group by 'imagen' and create a list of non-empty detections\n",
        "    df = df.groupby('imagen')['detected'].agg(lambda x: list(filter(None, x))).reset_index()\n",
        "\n",
        "    return df\n",
        "# Process all CSV files in the specified paths\n",
        "for path in paths:\n",
        "    if os.path.isfile(path) and path.endswith(\".csv\"):\n",
        "        df_modified = unify_detections(path)\n",
        "        directory, filename = os.path.split(path)\n",
        "        output_file_path = os.path.join(directory, f\"modified_{filename}\")\n",
        "        df_modified.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"All specified CSV files have been processed and saved with 'modified_' prefix.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa4J9XWyDos2",
        "outputId": "1b3cd577-0408-4166-d22e-4e7380bdb7ae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import ast\n",
        "\n",
        "# Define the categories and their corresponding file paths\n",
        "categories = {'your_paths'}\n",
        "\n",
        "# Read the original CSV file\n",
        "original_csv_path = '/content/drive/MyDrive/image_results/autonomy/modified_DetectionSummary.csv'\n",
        "original_df = pd.read_csv(original_csv_path)\n",
        "\n",
        "# Initialize a dictionary to store the combined data\n",
        "combined_data = {row['imagen']: {'autonomy': ast.literal_eval(row['detected'])} for _, row in original_df.iterrows()}\n",
        "\n",
        "# Process each category CSV file\n",
        "for category, path in categories.items():\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Add detected columns to combined_data\n",
        "    for index, row in df.iterrows():\n",
        "        imagen = row['imagen']\n",
        "        detected = ast.literal_eval(row['detected'])\n",
        "\n",
        "        if imagen not in combined_data:\n",
        "            combined_data[imagen] = {}\n",
        "\n",
        "        if category not in combined_data[imagen]:\n",
        "            combined_data[imagen][category] = []\n",
        "\n",
        "        # Only add non-empty detections\n",
        "        if detected and detected != []:\n",
        "            combined_data[imagen][category].extend(detected)\n",
        "\n",
        "# Create a new DataFrame from the combined data\n",
        "combined_df = pd.DataFrame(list(combined_data.items()), columns=['imagen', 'detections'])\n",
        "\n",
        "# Initialize the final DataFrame with the original data\n",
        "final_df = original_df.copy()\n",
        "\n",
        "# Add the detection columns and counts to the final DataFrame\n",
        "for category in ['autonomy'] + list(categories.keys()):\n",
        "    final_df[f'detected_{category}'] = final_df['imagen'].map(lambda x: combined_df.set_index('imagen').at[x, 'detections'].get(category, []) if x in combined_df.set_index('imagen').index else [])\n",
        "    final_df[f'count_detected_{category}'] = final_df[f'detected_{category}'].map(len)\n",
        "\n",
        "# Combine all detections into the original 'detected' column and add the total count\n",
        "final_df['detected'] = final_df.apply(lambda row: sum([row[f'detected_{cat}'] for cat in ['autonomy'] + list(categories.keys())], []), axis=1)\n",
        "final_df['count_detected'] = final_df['detected'].map(len)\n",
        "\n",
        "# Save the final DataFrame to a new CSV file\n",
        "output_csv_path = '/content/drive/MyDrive/image_results/finalcsv.csv'\n",
        "final_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(\"All category CSV files have been combined and saved with the detection counts.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgzGn6vNLuWq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import ast\n",
        "\n",
        "# Define the categories and their corresponding file paths\n",
        "categories = {'your_paths'}\n",
        "\n",
        "# Read the original CSV file\n",
        "original_csv_path = '/mnt/data/DetectionSummary (3).csv'\n",
        "original_df = pd.read_csv(original_csv_path)\n",
        "\n",
        "# Initialize a dictionary to store the combined data\n",
        "combined_data = {}\n",
        "\n",
        "# Process each category CSV file\n",
        "for category, path in categories.items():\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Add detected columns to combined_data\n",
        "    for index, row in df.iterrows():\n",
        "        imagen = row['imagen']\n",
        "        detected = row['detected']\n",
        "\n",
        "        if imagen not in combined_data:\n",
        "            combined_data[imagen] = {}\n",
        "\n",
        "        if category not in combined_data[imagen]:\n",
        "            combined_data[imagen][category] = []\n",
        "\n",
        "        # Only add non-empty detections\n",
        "        if detected and detected != '[]':\n",
        "            combined_data[imagen][category].append(detected)\n",
        "\n",
        "# Create a new DataFrame from the combined data\n",
        "combined_df = pd.DataFrame(list(combined_data.items()), columns=['imagen', 'detections'])\n",
        "\n",
        "# Initialize the final DataFrame with the original data\n",
        "final_df = original_df.copy()\n",
        "\n",
        "# Add the detection columns and counts to the final DataFrame\n",
        "for category in categories.keys():\n",
        "    final_df[f'detected_{category}'] = final_df['imagen'].map(lambda x: combined_df.set_index('imagen').at[x, 'detections'][category] if x in combined_df.set_index('imagen').index and category in combined_df.set_index('imagen').at[x, 'detections'] else [])\n",
        "    final_df[f'count_detected_{category}'] = final_df[f'detected_{category}'].map(lambda x: len(x))\n",
        "\n",
        "# Combine all detections into the original 'detected' column and add the total count\n",
        "final_df['detected'] = final_df.apply(lambda row: [det for cat in categories.keys() for det in row[f'detected_{cat}']], axis=1)\n",
        "final_df['count_detected'] = final_df['detected'].map(lambda x: len([i for i in x if i and i != '[]']))\n",
        "\n",
        "# Save the final DataFrame to a new CSV file\n",
        "output_csv_path = '/mnt/data/final_combined_detection_summary.csv'\n",
        "final_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(\"All category CSV files have been combined and saved with the detection counts.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
