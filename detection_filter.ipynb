{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2024-08-14-18-07-11.png)\n",
    "\n",
    "# DETECCION FILTER\n",
    "## Author: Diversa\n",
    "## Last Update: 03/10/2024\n",
    "## Proyect: Feminist Urban Sense\n",
    "## Contact: hello@diversa.studio\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection Filter Notebook\n",
    "\n",
    "## Descripción General\n",
    "\n",
    "Este notebook está diseñado para procesar y filtrar datos relacionados con la detección de ciertos patrones en imágenes o señales. Proporciona un pipeline para cargar los datos, aplicar algoritmos de detección, y filtrar los resultados según criterios específicos.\n",
    "\n",
    "### Contenido\n",
    "\n",
    "El notebook está dividido en las siguientes secciones:\n",
    "\n",
    "1. **Carga de Datos**: Se importan y preparan los datos necesarios para el análisis.\n",
    "2. **Preprocesamiento**: Se aplican métodos de limpieza y normalización de datos.\n",
    "3. **Algoritmo de Detección**: Se implementa el algoritmo para detectar patrones específicos en los datos.\n",
    "4. **Filtrado de Resultados**: Se aplica un filtro a los resultados para obtener aquellos que cumplan ciertos criterios.\n",
    "5. **Visualización**: Se generan visualizaciones para interpretar los resultados de manera clara y eficiente.\n",
    "6. **Exportación de Resultados**: Los resultados filtrados se exportan a un archivo para su posterior análisis.\n",
    "\n",
    "### Requisitos\n",
    "\n",
    "Este notebook está desarrollado en Python y requiere las siguientes librerías:\n",
    "\n",
    "- `pandas`\n",
    "\n",
    "### Cómo Usarlo\n",
    "\n",
    "1. Clonar o descargar el notebook.\n",
    "2. Asegurarse de tener instaladas las dependencias usando `pip` o `conda`:\n",
    "    ```bash\n",
    "    pip install pandas \n",
    "    ```\n",
    "3. Abrir el notebook en un entorno compatible como Jupyter o Colab.\n",
    "4. Ejecutar las celdas secuencialmente para cargar los datos, preprocesar, aplicar la detección y visualizar los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo de limpieza con múltiples hojas\n",
    "sheets_dict = pd.read_excel(\"your_path\", sheet_name=None)\n",
    "\n",
    "# Cargar la tabla de detecciones finales\n",
    "tabla_2 = pd.read_excel(\"your_path\")\n",
    "\n",
    "# Verificar los nombres originales de las columnas\n",
    "print(\"Nombres originales de columnas en tabla_2:\", tabla_2.columns)\n",
    "\n",
    "# No es necesario renombrar columnas porque ya tienen el formato correcto (con mayúscula 'Angle_0', etc.)\n",
    "\n",
    "# Convertir las columnas a cadenas para evitar errores con .str\n",
    "tabla_2['country'] = tabla_2['country'].astype(str).str.lower().str.strip()\n",
    "tabla_2['numero_img'] = tabla_2['numero_img'].astype(str).str.lower().str.strip()\n",
    "tabla_2['category'] = tabla_2['category'].astype(str).str.lower().str.strip()\n",
    "\n",
    "# Lista de países que esperamos encontrar\n",
    "paises = ['argentina', 'brasil', 'ec_co', 'peru', 'tailandia', 'vietnam']\n",
    "\n",
    "# Conteo de datos no nulos antes de la modificación\n",
    "conteo_inicial = tabla_2[['Angle_0', 'Angle_90', 'Angle_180', 'Angle_270']].notnull().sum()\n",
    "\n",
    "# Iteramos por cada hoja del archivo (cada categoría)\n",
    "for category, tabla_1 in sheets_dict.items():\n",
    "    # Limpiar los nombres de las columnas y los valores\n",
    "    tabla_1.columns = tabla_1.columns.str.lower().str.strip()\n",
    "    \n",
    "    # Limpieza de valores en tabla_1\n",
    "    tabla_1 = tabla_1.apply(lambda x: x.str.strip().str.lower() if x.dtype == \"object\" else x)\n",
    "\n",
    "    # Iteramos por cada país (columna) en la hoja actual\n",
    "    for country in paises:\n",
    "        if country in tabla_1.columns:\n",
    "            # Filtramos solo las filas donde haya datos de imágenes para ese país\n",
    "            country_data = tabla_1[[country]].dropna()\n",
    "\n",
    "            # Iteramos sobre cada imagen en esa columna del país\n",
    "            for _, row in country_data.iterrows():\n",
    "                # Extraemos el código de la imagen (e.g., streetview_35_90_out)\n",
    "                image_code = row[country]\n",
    "\n",
    "                # Comprobar si image_code no está vacío y es una cadena\n",
    "                if pd.notna(image_code) and isinstance(image_code, str):\n",
    "                    parts = image_code.split('_')\n",
    "                    # Validar que se obtuvieron al menos tres partes\n",
    "                    if len(parts) >= 3:\n",
    "                        numero_img = parts[1].strip()\n",
    "                        angulo = parts[2].strip()  # Mantener como cadena\n",
    "                        \n",
    "                        # Verificar que el ángulo está en el formato correcto (0, 90, 180, 270)\n",
    "                        if angulo in ['0', '90', '180', '270']:\n",
    "                            column_name = f\"Angle_{angulo}\"  # Formar el nombre de la columna con la \"A\" mayúscula\n",
    "                            \n",
    "                            # Verificar si la columna existe antes de modificar\n",
    "                            if column_name in tabla_2.columns:\n",
    "                                # Comprobar si la fila existe antes de modificar\n",
    "                                mask = (\n",
    "                                    (tabla_2['country'] == country) &\n",
    "                                    (tabla_2['numero_img'] == numero_img) &\n",
    "                                    (tabla_2['category'] == category)\n",
    "                                )\n",
    "                                \n",
    "                                # Solo modificar si existe la coincidencia\n",
    "                                if mask.any():\n",
    "                                    # Imprimir valor antes del cambio\n",
    "                                    valor_antes = tabla_2.loc[mask, column_name].values[0]\n",
    "                                    print(f\"Valor antes del cambio: {valor_antes} para {country}, numero_img: {numero_img}, ángulo: {angulo}\")\n",
    "                                    \n",
    "                                    # Realizar la modificación con np.nan\n",
    "                                    tabla_2.loc[mask, column_name] = np.nan  # Reemplaza por NaN explícitamente\n",
    "                                    \n",
    "                                    # Imprimir valor después del cambio\n",
    "                                    valor_despues = tabla_2.loc[mask, column_name].values[0]\n",
    "                                    print(f\"Valor después del cambio: {valor_despues} para {country}, numero_img: {numero_img}, ángulo: {angulo}\")\n",
    "                                    \n",
    "                                    # Verificación de éxito\n",
    "                                    if pd.isna(tabla_2.loc[mask, column_name]).all():\n",
    "                                        print(f\"Fila modificada correctamente para {country}, numero_img: {numero_img}, ángulo: {angulo}\")\n",
    "                                    else:\n",
    "                                        print(f\"Error: la fila no fue modificada para {country}, numero_img: {numero_img}, ángulo: {angulo}\")\n",
    "                                else:\n",
    "                                    print(f\"No se encontró coincidencia para {country}, numero_img: {numero_img}, ángulo: {angulo}\")\n",
    "                            else:\n",
    "                                print(f\"Columna '{column_name}' no encontrada.\")\n",
    "                        else:\n",
    "                            print(f\"Ángulo inesperado: '{angulo}' en el código de imagen: '{image_code}'\")\n",
    "                    else:\n",
    "                        print(f\"Formato inesperado en el código de imagen: '{image_code}'. Debe contener al menos 3 partes.\")\n",
    "                else:\n",
    "                    print(f\"image_code vacío o no es una cadena: '{image_code}'\")\n",
    "\n",
    "# Guardamos la tabla limpia\n",
    "tabla_2.to_csv(\"tabla_limpia_f.csv\", index=False)\n",
    "\n",
    "# Conteo de datos no nulos después de la modificación\n",
    "conteo_final = tabla_2[['Angle_0', 'Angle_90', 'Angle_180', 'Angle_270']].notnull().sum()\n",
    "print(\"Conteo de datos no nulos después de la modificación:\")\n",
    "print(conteo_final)\n",
    "\n",
    "# Mostrar las diferencias\n",
    "diferencias = conteo_inicial - conteo_final\n",
    "print(\"Diferencia de datos eliminados:\")\n",
    "print(diferencias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rosario\n",
      "JaraguÃ¡ do Sul\n",
      "MedellÃ­n\n",
      "Mandalay\n",
      "Bangkok\n",
      "HanÃ³i\n",
      "Piura\n",
      "Quito\n",
      "Cuenca\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('your_path_here.csv')\n",
    "\n",
    "# Obtener una lista de ciudades únicas\n",
    "unique_cities = df['city'].unique()\n",
    "\n",
    "# Imprimir las ciudades únicas\n",
    "for city in unique_cities:\n",
    "    print(city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('your_path_here.csv')\n",
    "\n",
    "# Palabras a corregir (incorrectas a corregir)\n",
    "correcciones = {\n",
    "    'Rosario': 'rosario',\n",
    "    'JaraguÃ¡ do Sul': 'jaragua_do_sul',\n",
    "    'MedellÃ­n': 'medellin',\n",
    "    'Mandalay': 'mandalay',\n",
    "    'Bangkok': 'bangkok',\n",
    "    'HanÃ³i': 'hanoi',\n",
    "    'Piura': 'piura',\n",
    "    'Quito': 'quito',\n",
    "    'Cuenca': 'cuenca'\n",
    "}\n",
    "\n",
    "# Corregir las palabras en las columnas\n",
    "def corregir_palabras(texto):\n",
    "    # Reemplazar la palabra errónea por la correcta\n",
    "    for palabra_erronea, palabra_correcta in correcciones.items():\n",
    "        texto = texto.replace(palabra_erronea, palabra_correcta)\n",
    "    return texto\n",
    "\n",
    "# Aplicar la corrección en las columnas 'city' e 'indice'\n",
    "df['city'] = df['city'].apply(corregir_palabras)\n",
    "df['indice'] = df['indice'].apply(corregir_palabras)\n",
    "\n",
    "# Mostrar el DataFrame corregido\n",
    "print(df)\n",
    "\n",
    "# Guardar el DataFrame corregido en un nuevo archivo CSV\n",
    "df.to_csv('detecciones_finales.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
